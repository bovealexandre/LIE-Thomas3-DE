{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DiabetesDiagnosis\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"diabetes.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df = df.drop(\"Pregnancies\", \"SkinThickness\")\n",
    "\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, exp\n",
    "def iqr_outlier_treatment(dataframe, columns, factor=1.5):\n",
    "    \"\"\"\n",
    "    Detects and treats outliers using IQR for multiple variables in a PySpark DataFrame.\n",
    "\n",
    "    :param dataframe: The input PySpark DataFrame\n",
    "    :param columns: A list of columns to apply IQR outlier treatment\n",
    "    :param factor: The IQR factor to use for detecting outliers (default is 1.5)\n",
    "    :return: The processed DataFrame with outliers treated\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        # Calculate Q1, Q3, and IQR\n",
    "        quantiles = dataframe.approxQuantile(column, [0.25, 0.75], 0.01)\n",
    "        q1, q3 = quantiles[0], quantiles[1]\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # Define the upper and lower bounds for outliers\n",
    "        lower_bound = q1 - factor * iqr\n",
    "        upper_bound = q3 + factor * iqr\n",
    "\n",
    "        # Filter outliers and update the DataFrame\n",
    "        dataframe = dataframe.filter((col(column) >= lower_bound) & (col(column) <= upper_bound))\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "df = iqr_outlier_treatment(df, [\"BloodPressure\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\"], factor=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, lit\n",
    "\n",
    "\n",
    "columns_to_replace = [\"BloodPressure\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\"]\n",
    "for col_name in columns_to_replace:\n",
    "    mean_val = df.filter(df[col_name] != 0).groupBy().mean(col_name).first()[0]\n",
    "    df = df.withColumn(col_name, when(df[col_name] == 0, lit(mean_val)).otherwise(df[col_name]))\n",
    "    \n",
    "df = df.withColumn(\"BloodPressure/Insulin\", (col(\"BloodPressure\") / col(\"Insulin\")))\n",
    "df = df.withColumn(\"BloodPressure/BMI\", (col(\"BloodPressure\") / col(\"BMI\")))\n",
    "df = df.withColumn(\"Insulin/BMI\", (col(\"Insulin\") / col(\"BMI\")))\n",
    "df = df.withColumn(\"Insulin/Glucose\", (col(\"Insulin\") / col(\"Glucose\")))\n",
    "df = df.withColumn(\"BMI/Glucose\", (col(\"BMI\") / col(\"Glucose\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "\n",
    "\n",
    "# Select the useful columns for the vector assembler\n",
    "useful_columns = [\"Glucose\", \"BloodPressure\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"BloodPressure/Insulin\", \"BloodPressure/BMI\"]\n",
    "\n",
    "# Create the vector assembler\n",
    "assembler = VectorAssembler(inputCols=useful_columns, outputCol=\"features\")\n",
    "\n",
    "# Transform the dataframe to include the vector column\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Split the data between test and train\n",
    "train, test = df.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Logistic Regression ============================== \n",
      "accuracy = 78.11%\n",
      "precision = 77.48%\n",
      "recall = 78.11% \n",
      "=================================================================================\n",
      "\n",
      "\n",
      "================================= Decision Tree =================================\n",
      "accuracy = 66.86%\n",
      "precision = 69.73%\n",
      "recall = 66.86%\n",
      "=================================================================================\n",
      "\n",
      "\n",
      "================================ Random Forest ==================================\n",
      "accuracy = 75.74%\n",
      "precision = 74.87%\n",
      "recall = 75.74%\n",
      "=================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr = LogisticRegression(labelCol=\"Outcome\", featuresCol=\"features\")\n",
    "lr_model = lr.fit(train)\n",
    "\n",
    "# Train Decision Tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"Outcome\", featuresCol=\"features\")\n",
    "dt_model = dt.fit(train)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf = RandomForestClassifier(labelCol=\"Outcome\", featuresCol=\"features\")\n",
    "rf_model = rf.fit(train)\n",
    "\n",
    "# Evaluate models\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Outcome\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate metrics for Logistic Regression\n",
    "lr_accuracy = evaluator.evaluate(lr_model.transform(test), {evaluator.metricName: \"accuracy\"})\n",
    "lr_precision = evaluator.evaluate(lr_model.transform(test), {evaluator.metricName: \"weightedPrecision\"})\n",
    "lr_recall = evaluator.evaluate(lr_model.transform(test), {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Calculate metrics for Decision Tree\n",
    "dt_accuracy = evaluator.evaluate(dt_model.transform(test), {evaluator.metricName: \"accuracy\"})\n",
    "dt_precision = evaluator.evaluate(dt_model.transform(test), {evaluator.metricName: \"weightedPrecision\"})\n",
    "dt_recall = evaluator.evaluate(dt_model.transform(test), {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Calculate metrics for Random Forest\n",
    "rf_accuracy = evaluator.evaluate(rf_model.transform(test), {evaluator.metricName: \"accuracy\"})\n",
    "rf_precision = evaluator.evaluate(rf_model.transform(test), {evaluator.metricName: \"weightedPrecision\"})\n",
    "rf_recall = evaluator.evaluate(rf_model.transform(test), {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Print model performances\n",
    "print(f\"\"\"\n",
    "============================== Logistic Regression ============================== \n",
    "accuracy = {lr_accuracy * 100:.2f}%\n",
    "precision = {lr_precision * 100:.2f}%\n",
    "recall = {lr_recall * 100:.2f}% \n",
    "=================================================================================\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"\n",
    "================================= Decision Tree =================================\n",
    "accuracy = {dt_accuracy * 100:.2f}%\n",
    "precision = {dt_precision * 100:.2f}%\n",
    "recall = {dt_recall * 100:.2f}%\n",
    "=================================================================================\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"\n",
    "================================ Random Forest ==================================\n",
    "accuracy = {rf_accuracy * 100:.2f}%\n",
    "precision = {rf_precision * 100:.2f}%\n",
    "recall = {rf_recall * 100:.2f}%\n",
    "=================================================================================\n",
    "\"\"\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
